version = "3.3"


# PRIVATE

[resources]
processes = 0
relative_paths = false # in stat files, output paths relative to the workspace root

[resources.cases]
input = "data/input"
output = "data/output"

[resources.conceptnet]
url = "neo4j://localhost:7687"
username = "neo4j"
password = ""

[resources.spacy]
host = "0.0.0.0"
port = 8765
workers = 1


# PUBLIC

[export]
graph_json = true
graph_pdf = false
grid_stats = true
baseline = true
aggr_funcs = ["mean"]
retrieval_improvement = true
single_stats = true

[adaptation]
knowledge_graph = "conceptnet"

[loading]
# only set to true if the user-defined rules do NOT represent a path in the KG
enforce_node_paths = false


[tuning]
adaptation_lemma_limit = [5]
adaptation_method = ["direct"] # direct, bfs
adaptation_pruning_bfs_limit = [10]
adaptation_weight_original_concept = [1]
adaptation_weight_rule_target = [1]
# How to prune the paths and/or lemmas of found concepts
# difference: The vector direction between the concepts should match, i.e. min cosine(abs(vec1 - vec2), abs(vec3 - vec4)).
# similarity: The absolute similarity values of the concepts should match, i.e. min abs(cosine(vec1, vec2) - cosine(vec3, vec4)).
adaptation_pruning_selector = ["difference"]

# NOUN, PROPN (not in WordNet), VERB, ADJ, ADV
extraction_keyword_pos_tags = [["NOUN"]]
extraction_keywords_per_adu = [false]
extraction_max_concepts = [1000]

global_rule_limit = [1]

# Of which metrics should the score consist
# score_adus_sem_sim = [0, 1]
score_concept_sem_sim = [1]
# score_hypernym_prox = [0, 1]
# score_keyword_weight = [1]
# score_major_claim_prox = [0, 1]
score_nodes_path_sim = [0, 1]
# score_nodes_sem_sim = [0, 1]
# score_query_adus_sem_sim = [0, 1]
# score_query_concept_sem_sim = [1]
# score_query_nodes_sem_sim = [0, 1]

threshold_concept_score = [0.0] # Filtering concepts
threshold_node_similarity = [0.0] # Assigning nodes
# threshold_concept_score_adaptation = [0.0, 0.3, 0.6, 0.9] # Filtering concepts
# threshold_concept_score_extraction = [0.0, 0.3, 0.6, 0.9] # Filtering concepts
# threshold_node_similarity_adaptation = [0.0, 0.33, 0.67, 1.0] # Assigning nodes
# threshold_node_similarity_extraction = [0.0, 0.33, 0.67, 1.0] # Assigning nodes

# between: Try to transfer the concept path from (adaptation origin, adaptation destination) to (current concept, adapted concept).
# within: Try to transfer the concept path from (adaptation origin, current concept) to (adaptation destination, adapted concept).
# bfs_method = ["between"] # within CANNOT be used for generalization!


[nlp]
lang = "en"
embeddings = "glove" # glove, sbert, use
fuzzymax = false

[nlp.inflections]
[nlp.inflections.prove]
proven = ["VBN"]


[wordnet]
hypernym_filter = [
    "entity.n.01",
    "artifact.n.01",
    "causal_agent.n.01",
    "living_thing.n.01",
    "object.n.01",
    "physical_entity.n.01",
    "psychological_feature.n.01",
]
node_vector_components = ["examples", "definition"]


[conceptnet]
[conceptnet.node]
follow_form_of = false

[conceptnet.relation]
directed = true
generalization_types = ["IsA"] # "HasA", "DerivedFrom", "IsA", "PartOf"
all_types = [
    "Antonym",
    "AtLocation",
    "CapableOf",
    "Causes",
    "CausesDesire",
    "CreatedBy",
    "DefinedAs",
    "DerivedFrom",
    "Desires",
    "DistinctFrom",
    "Entails",
    "EtymologicallyDerivedFrom",
    "EtymologicallyRelatedTo",
    "ExternalURL",
    "FormOf",
    "HasA",
    "HasContext",
    "HasFirstSubevent",
    "HasLastSubevent",
    "HasPrerequisite",
    "HasProperty",
    "HasSubevent",
    "IsA",
    "IsInstanceOf",
    "LocatedNear",
    "MadeOf",
    "MannerOf",
    "MotivatedByGoal",
    "NotCapableOf",
    "NotDesires",
    "NotHasProperty",
    "ObstructedBy",
    "PartOf",
    "ReceivesAction",
    "RelatedTo",
    "SimilarTo",
    "SymbolOf",
    "Synonym",
    "UsedFor",
]

[conceptnet.path]
[conceptnet.path.max_length]
shortest_path = 20
generalization = 10
metrics = 10
